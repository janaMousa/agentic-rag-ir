{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e30e9f",
   "metadata": {},
   "source": [
    "×¡×˜×•×“× ×˜×™×:\n",
    "×’× × ×\\×¤××™×– × \\××’'×“ ×"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b49a9e",
   "metadata": {},
   "source": [
    "3. agentic RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1a1dca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ .env loaded: True\n",
      "âœ“ GROQ_API_KEY loaded (length: 56)\n",
      "âœ“ Environment setup complete\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 1: Imports + .env setup\n",
    "# =========================\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Literal\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env in project root\n",
    "env_path = Path.cwd() / \".env\"\n",
    "loaded = load_dotenv(dotenv_path=env_path, override=True)\n",
    "\n",
    "groq_key = os.getenv(\"GROQ_API_KEY\")\n",
    "assert groq_key, (\n",
    "    \"âŒ GROQ_API_KEY not found. \"\n",
    "    \"Make sure .env exists in project root and contains GROQ_API_KEY=...\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ .env loaded:\", loaded)\n",
    "print(f\"âœ“ GROQ_API_KEY loaded (length: {len(groq_key)})\")\n",
    "print(\"âœ“ Environment setup complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fb3d699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded docs: 1\n",
      "âœ“ Chunks: 5\n",
      "âœ“ Example chunk chars: 749\n",
      "âœ“ Preview:\n",
      " Information Retrieval (IR) Notes\n",
      "\n",
      "Information Retrieval deals with finding relevant documents for a given user query.\n",
      "The goal of IR systems is to rank documents by relevance rather than return exact matches.\n",
      "\n",
      "An inverted index is the core data struc\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 2: Load docs + chunking\n",
    "# =========================\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "DOC_PATH = Path(\"data\") / \"docs.txt\"\n",
    "assert DOC_PATH.exists(), f\"âŒ Missing file: {DOC_PATH.resolve()}\"\n",
    "\n",
    "docs = TextLoader(str(DOC_PATH), encoding=\"utf-8\").load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=120,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "print(\"âœ“ Loaded docs:\", len(docs))\n",
    "print(\"âœ“ Chunks:\", len(chunks))\n",
    "print(\"âœ“ Example chunk chars:\", len(chunks[0].page_content))\n",
    "print(\"âœ“ Preview:\\n\", chunks[0].page_content[:250])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9fba3295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb10ea0acf494e23b041b6aed2d4aa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing FAISS index...\n",
      "âœ“ Loaded existing FAISS index.\n",
      "âœ“ Retriever working. Retrieved: 3 chunks\n",
      "âœ“ First hit preview:\n",
      " Stemming reduces words to their root form, for example \"retrieval\" to \"retriev\".\n",
      "Lemmatization reduces words to their dictionary form and is linguistically informed.\n",
      "\n",
      "Term Frequency (TF) measures how \n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 3: Build / load FAISS + retriever\n",
    "# =========================\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "INDEX_DIR = Path(\"vectorstore_faiss\")\n",
    "\n",
    "# Local embeddings model (downloads once)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Load existing index if found, else build new\n",
    "if INDEX_DIR.exists() and (INDEX_DIR / \"index.faiss\").exists():\n",
    "    print(\"Loading existing FAISS index...\")\n",
    "    vectorstore = FAISS.load_local(str(INDEX_DIR), embeddings, allow_dangerous_deserialization=True)\n",
    "    print(\"âœ“ Loaded existing FAISS index.\")\n",
    "else:\n",
    "    print(\"Building new FAISS index...\")\n",
    "    INDEX_DIR.mkdir(exist_ok=True)\n",
    "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "    vectorstore.save_local(str(INDEX_DIR))\n",
    "    print(\"âœ“ Built + saved new FAISS index to:\", INDEX_DIR.resolve())\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# quick retrieval test\n",
    "hits = retriever.invoke(\"What is TF-IDF?\")\n",
    "print(\"âœ“ Retriever working. Retrieved:\", len(hits), \"chunks\")\n",
    "print(\"âœ“ First hit preview:\\n\", hits[0].page_content[:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "522fc16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RAG function...\n",
      "âœ“ RAG function working\n",
      "Answer preview:\n",
      " TF-IDF (Term Frequency-Inverse Document Frequency) is a weighting scheme used in Information Retrieval to measure the importance of a term in a document. It is computed as the product of Term Frequenc ...\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 4: RAG Answer function (Groq)\n",
    "# =========================\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "def rag_answer(question: str, k: int = 3) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    RAG = retrieve top-k chunks from FAISS, then ask Groq to answer using ONLY those chunks.\n",
    "    Returns: {\"answer\": str, \"sources\": [str, ...]}\n",
    "    \"\"\"\n",
    "    # 1) Retrieve\n",
    "    top_docs = retriever.invoke(question)[:k]\n",
    "\n",
    "    # 2) Format sources\n",
    "    context_blocks = []\n",
    "    for i, d in enumerate(top_docs, 1):\n",
    "        context_blocks.append(f\"[Source {i}]\\n{d.page_content.strip()}\")\n",
    "\n",
    "    context = \"\\n\\n\".join(context_blocks)\n",
    "\n",
    "    # 3) Grounded prompt\n",
    "    system = (\n",
    "        \"You are a RAG assistant for an Information Retrieval homework. \"\n",
    "        \"Answer using ONLY the provided sources. \"\n",
    "        \"If the sources do not contain the answer, say you don't have enough information. \"\n",
    "        \"Cite sources like [Source 1], [Source 2].\"\n",
    "    )\n",
    "\n",
    "    user = f\"\"\"Question: {question}\n",
    "\n",
    "Sources:\n",
    "{context}\n",
    "\n",
    "Write a concise answer with citations.\"\"\"\n",
    "\n",
    "    # 4) Generate\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"llama-3.1-8b-instant\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": user},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    return {\"answer\": resp.choices[0].message.content, \"sources\": context_blocks}\n",
    "\n",
    "# Quick test\n",
    "print(\"Testing RAG function...\")\n",
    "test_result = rag_answer(\"What is TF-IDF?\")\n",
    "print(\"âœ“ RAG function working\")\n",
    "print(\"Answer preview:\\n\", test_result[\"answer\"][:200], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ad58bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Weather API test: Haifa 18.1Â°C, wind 10.0 km/h\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 5: Weather API (Open-Meteo) + Geocoding\n",
    "# =========================\n",
    "def get_weather_open_meteo(city: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    API #1: Open-Meteo\n",
    "    1) Geocoding API: city -> lat/lon\n",
    "    2) Forecast API: lat/lon -> current weather\n",
    "    No API key required.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1) Geocode city -> lat/lon\n",
    "        geo_url = \"https://geocoding-api.open-meteo.com/v1/search\"\n",
    "        geo = requests.get(\n",
    "            geo_url,\n",
    "            params={\"name\": city, \"count\": 1, \"language\": \"en\", \"format\": \"json\"},\n",
    "            timeout=10\n",
    "        )\n",
    "        geo.raise_for_status()\n",
    "        geo_data = geo.json()\n",
    "\n",
    "        if not geo_data.get(\"results\"):\n",
    "            return {\"error\": f\"City not found: {city}\"}\n",
    "\n",
    "        r0 = geo_data[\"results\"][0]\n",
    "        lat, lon = r0[\"latitude\"], r0[\"longitude\"]\n",
    "\n",
    "        # 2) Current weather\n",
    "        forecast_url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "        fc = requests.get(\n",
    "            forecast_url,\n",
    "            params={\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lon,\n",
    "                \"current\": \"temperature_2m,wind_speed_10m\",\n",
    "                \"timezone\": \"auto\",\n",
    "            },\n",
    "            timeout=10\n",
    "        )\n",
    "        fc.raise_for_status()\n",
    "        fc_data = fc.json()\n",
    "\n",
    "        cur = fc_data.get(\"current\", {})\n",
    "        return {\n",
    "            \"city\": r0.get(\"name\"),\n",
    "            \"country\": r0.get(\"country\"),\n",
    "            \"lat\": lat,\n",
    "            \"lon\": lon,\n",
    "            \"temperature_c\": cur.get(\"temperature_2m\"),\n",
    "            \"wind_kmh\": cur.get(\"wind_speed_10m\"),\n",
    "            \"time\": cur.get(\"time\"),\n",
    "            \"source\": \"open-meteo\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Weather API error: {e}\"}\n",
    "\n",
    "# Quick test\n",
    "w = get_weather_open_meteo(\"Haifa\")\n",
    "print(\"âœ“ Weather API test:\", w if \"error\" in w else f\"{w['city']} {w['temperature_c']}Â°C, wind {w['wind_kmh']} km/h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac9842d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Crypto API test: bitcoin $77858, 24h -7.59%\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 6: Crypto API (CoinGecko) - BONUS\n",
    "# =========================\n",
    "def get_crypto_price(symbol: str = \"bitcoin\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    API #2 (BONUS): CoinGecko simple price endpoint.\n",
    "    No API key required.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = \"https://api.coingecko.com/api/v3/simple/price\"\n",
    "        params = {\"ids\": symbol.lower(), \"vs_currencies\": \"usd\", \"include_24hr_change\": \"true\"}\n",
    "        resp = requests.get(url, params=params, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "\n",
    "        if symbol.lower() not in data:\n",
    "            return {\"error\": f\"Crypto not found: {symbol}\"}\n",
    "\n",
    "        coin = data[symbol.lower()]\n",
    "        return {\n",
    "            \"symbol\": symbol.lower(),\n",
    "            \"price_usd\": coin.get(\"usd\"),\n",
    "            \"change_24h\": coin.get(\"usd_24h_change\"),\n",
    "            \"source\": \"coingecko\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Crypto API error: {e}\"}\n",
    "\n",
    "# Quick test\n",
    "c = get_crypto_price(\"bitcoin\")\n",
    "print(\"âœ“ Crypto API test:\", c if \"error\" in c else f\"bitcoin ${c['price_usd']}, 24h {c['change_24h']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c6930ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Extractors ready: Tel Aviv | ethereum\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 7: Extract helpers (city + crypto)\n",
    "# =========================\n",
    "def extract_city(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts a city from patterns like:\n",
    "    'weather in Tel Aviv', 'forecast for Paris'\n",
    "    Fallback: Haifa\n",
    "    \"\"\"\n",
    "    m = re.search(r\"\\b(in|at|for)\\s+([A-Za-z\\s\\-]+)\", user_query.strip(), re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(2).strip()\n",
    "\n",
    "    common = [\"haifa\", \"tel aviv\", \"jerusalem\", \"london\", \"new york\", \"paris\", \"tokyo\"]\n",
    "    q = user_query.lower()\n",
    "    for city in common:\n",
    "        if city in q:\n",
    "            return city.title()\n",
    "\n",
    "    return \"Haifa\"\n",
    "\n",
    "def extract_crypto(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Maps common symbols/names to CoinGecko ids.\n",
    "    Fallback: bitcoin\n",
    "    \"\"\"\n",
    "    q = user_query.lower()\n",
    "    crypto_map = {\n",
    "        \"bitcoin\": \"bitcoin\", \"btc\": \"bitcoin\",\n",
    "        \"ethereum\": \"ethereum\", \"eth\": \"ethereum\",\n",
    "        \"solana\": \"solana\", \"sol\": \"solana\",\n",
    "        \"cardano\": \"cardano\", \"ada\": \"cardano\",\n",
    "        \"dogecoin\": \"dogecoin\", \"doge\": \"dogecoin\",\n",
    "    }\n",
    "    for key, coin_id in crypto_map.items():\n",
    "        if key in q:\n",
    "            return coin_id\n",
    "    return \"bitcoin\"\n",
    "\n",
    "print(\"âœ“ Extractors ready:\",\n",
    "      extract_city(\"weather in Tel Aviv\"), \"|\",\n",
    "      extract_crypto(\"price of ETH\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce222691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routing proof:\n",
      "- Query: What's the weather in Haifa?\n",
      "  Route chosen: weather\n",
      "- Query: What is the price of bitcoin?\n",
      "  Route chosen: crypto\n",
      "- Query: Explain BM25 algorithm\n",
      "  Route chosen: rag\n",
      "âœ“ Routing logic working\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 8: Routing logic (agent chooses tool)\n",
    "# =========================\n",
    "def route_task(user_query: str) -> Literal[\"weather\", \"crypto\", \"rag\"]:\n",
    "    q = user_query.lower()\n",
    "\n",
    "    crypto_keywords = [\"crypto\", \"cryptocurrency\", \"bitcoin\", \"ethereum\", \"price of\", \"btc\", \"eth\", \"coin\", \"solana\", \"doge\", \"cardano\"]\n",
    "    if any(k in q for k in crypto_keywords):\n",
    "        return \"crypto\"\n",
    "\n",
    "    weather_keywords = [\"weather\", \"temperature\", \"forecast\", \"rain\", \"wind\", \"humidity\", \"hot\", \"cold\"]\n",
    "    if any(k in q for k in weather_keywords):\n",
    "        return \"weather\"\n",
    "\n",
    "    return \"rag\"\n",
    "\n",
    "# Routing proof (grader-friendly)\n",
    "test_queries = [\n",
    "    \"What's the weather in Haifa?\",\n",
    "    \"What is the price of bitcoin?\",\n",
    "    \"Explain BM25 algorithm\"\n",
    "]\n",
    "print(\"Routing proof:\")\n",
    "for tq in test_queries:\n",
    "    print(f\"- Query: {tq}\")\n",
    "    print(f\"  Route chosen: {route_task(tq)}\")\n",
    "print(\"âœ“ Routing logic working\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f137fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ agentic_answer ready\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 9: Main agentic_answer (routes to tools)\n",
    "# =========================\n",
    "def agentic_answer(user_query: str) -> Dict[str, Any]:\n",
    "    decision = route_task(user_query)\n",
    "\n",
    "    if decision == \"weather\":\n",
    "        city = extract_city(user_query)\n",
    "        weather = get_weather_open_meteo(city)\n",
    "        return {\n",
    "            \"tool_used\": \"weather_api\",\n",
    "            \"decision\": f\"Weather keywords detected â†’ Open-Meteo API for {city}\",\n",
    "            \"result\": weather\n",
    "        }\n",
    "\n",
    "    if decision == \"crypto\":\n",
    "        coin = extract_crypto(user_query)\n",
    "        crypto = get_crypto_price(coin)\n",
    "        return {\n",
    "            \"tool_used\": \"crypto_api\",\n",
    "            \"decision\": f\"Crypto keywords detected â†’ CoinGecko API for {coin}\",\n",
    "            \"result\": crypto\n",
    "        }\n",
    "\n",
    "    rag = rag_answer(user_query, k=3)\n",
    "    return {\n",
    "        \"tool_used\": \"rag\",\n",
    "        \"decision\": \"Default route â†’ RAG retrieval + Groq answer grounded in sources\",\n",
    "        \"result\": rag\n",
    "    }\n",
    "\n",
    "print(\"âœ“ agentic_answer ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dee3235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ show_agentic_result ready\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 10: Pretty display function\n",
    "# =========================\n",
    "def show_agentic_result(res: Dict[str, Any]) -> None:\n",
    "    print(\"â•”\" + \"â•\" * 62 + \"â•—\")\n",
    "    print(f\"â•‘ TOOL USED: {res['tool_used'].upper():49} â•‘\")\n",
    "    print(\"â• \" + \"â•\" * 62 + \"â•£\")\n",
    "\n",
    "    decision = res[\"decision\"]\n",
    "    lines = [decision[i:i+52] for i in range(0, len(decision), 52)]\n",
    "    print(f\"â•‘ DECISION: {lines[0]:52} â•‘\")\n",
    "    for extra in lines[1:]:\n",
    "        print(f\"â•‘           {extra:52} â•‘\")\n",
    "    print(\"â•š\" + \"â•\" * 62 + \"â•\\n\")\n",
    "\n",
    "    if res[\"tool_used\"] == \"weather_api\":\n",
    "        w = res[\"result\"]\n",
    "        if \"error\" in w:\n",
    "            print(\"âŒ\", w[\"error\"])\n",
    "            return\n",
    "        print(f\"ğŸŒ¤ï¸  Weather in {w['city']}, {w['country']}\")\n",
    "        print(f\"   ğŸ“ {w['lat']:.2f}, {w['lon']:.2f}\")\n",
    "        print(f\"   ğŸŒ¡ï¸  {w['temperature_c']} Â°C\")\n",
    "        print(f\"   ğŸ’¨ {w['wind_kmh']} km/h\")\n",
    "        print(f\"   ğŸ• {w['time']}\")\n",
    "        print(f\"   ğŸ“¡ {w['source']}\")\n",
    "\n",
    "    elif res[\"tool_used\"] == \"crypto_api\":\n",
    "        c = res[\"result\"]\n",
    "        if \"error\" in c:\n",
    "            print(\"âŒ\", c[\"error\"])\n",
    "            return\n",
    "        emoji = \"ğŸ“ˆ\" if (c.get(\"change_24h\") or 0) > 0 else \"ğŸ“‰\"\n",
    "        print(f\"ğŸ’° {c['symbol'].upper()}\")\n",
    "        print(f\"   ğŸ’µ ${c['price_usd']:,.2f}\")\n",
    "        print(f\"   {emoji} {c['change_24h']:.2f}% (24h)\")\n",
    "        print(f\"   ğŸ“¡ {c['source']}\")\n",
    "\n",
    "    else:\n",
    "        rag = res[\"result\"]\n",
    "        print(\"ğŸ“š RAG Answer:\\n\" + \"â”€\" * 60)\n",
    "        print(rag[\"answer\"])\n",
    "        print(\"\\n\" + \"â”€\" * 60)\n",
    "        print(\"ğŸ“– Sources:\")\n",
    "        for s in rag[\"sources\"]:\n",
    "            snippet = s if len(s) <= 350 else s[:350] + \"...\"\n",
    "            print(\"\\n\" + snippet)\n",
    "\n",
    "print(\"âœ“ show_agentic_result ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1204b71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯\n",
      "AGENTIC RAG SYSTEM - FINAL DEMO\n",
      "ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯\n",
      "\n",
      "======================================================================\n",
      "DEMO 1: WEATHER API\n",
      "======================================================================\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ TOOL USED: WEATHER_API                                       â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘ DECISION: Weather keywords detected â†’ Open-Meteo API for Tel A â•‘\n",
      "â•‘           viv                                                  â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸŒ¤ï¸  Weather in Tel Aviv, Israel\n",
      "   ğŸ“ 32.08, 34.78\n",
      "   ğŸŒ¡ï¸  19.5 Â°C\n",
      "   ğŸ’¨ 5.2 km/h\n",
      "   ğŸ• 2026-01-31T21:30\n",
      "   ğŸ“¡ open-meteo\n",
      "\n",
      "======================================================================\n",
      "DEMO 2: CRYPTO API (BONUS)\n",
      "======================================================================\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ TOOL USED: CRYPTO_API                                        â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘ DECISION: Crypto keywords detected â†’ CoinGecko API for ethereu â•‘\n",
      "â•‘           m                                                    â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ’° ETHEREUM\n",
      "   ğŸ’µ $2,402.16\n",
      "   ğŸ“‰ -12.61% (24h)\n",
      "   ğŸ“¡ coingecko\n",
      "\n",
      "======================================================================\n",
      "DEMO 3: RAG (IR)\n",
      "======================================================================\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ TOOL USED: RAG                                               â•‘\n",
      "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
      "â•‘ DECISION: Default route â†’ RAG retrieval + Groq answer grounded â•‘\n",
      "â•‘            in sources                                          â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ“š RAG Answer:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "BM25 is a probabilistic ranking function used in many search engines to improve the TF-IDF scoring function [Source 2]. It assigns diminishing returns to repeated occurrences of a term in a document and penalizes very long documents to avoid length bias [Source 1]. BM25 models term saturation and document length normalization, which are not considered in TF-IDF.\n",
      "\n",
      "BM25 works by computing a score for each document based on the term frequency (TF) and inverse document frequency (IDF) of the query terms in the document. However, the exact formula for BM25 is not provided in the given sources. \n",
      "\n",
      "The BM25 score is then used to rank documents in descending order of relevance, with the most relevant documents appearing at the top of the ranking. This ranking is evaluated using metrics such as Mean Average Precision (MAP) and Normalized Discounted Cumulative Gain (nDCG), which consider graded relevance and reward placing highly relevant documents near the top of the ranking [Source 1].\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“– Sources:\n",
      "\n",
      "[Source 1]\n",
      "BM25 assigns diminishing returns to repeated occurrences of a term in a document.\n",
      "It also penalizes very long documents to avoid length bias.\n",
      "\n",
      "Precision is the fraction of retrieved documents that are relevant.\n",
      "Recall is the fraction of relevant documents that are retrieved.\n",
      "\n",
      "There is usually a trade-off between precision and recall.\n",
      "Imp...\n",
      "\n",
      "[Source 2]\n",
      "Stemming reduces words to their root form, for example \"retrieval\" to \"retriev\".\n",
      "Lemmatization reduces words to their dictionary form and is linguistically informed.\n",
      "\n",
      "Term Frequency (TF) measures how often a term appears in a document.\n",
      "Inverse Document Frequency (IDF) measures how rare a term is across the document collection.\n",
      "\n",
      "TF-IDF is...\n",
      "\n",
      "[Source 3]\n",
      "Information Retrieval (IR) Notes\n",
      "\n",
      "Information Retrieval deals with finding relevant documents for a given user query.\n",
      "The goal of IR systems is to rank documents by relevance rather than return exact matches.\n",
      "\n",
      "An inverted index is the core data structure in IR systems.\n",
      "It maps each term to a posting list of documents in which the term ap...\n",
      "\n",
      "âœ… All demos completed.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 11: FINAL DEMO (shows all 3 tools)\n",
    "# =========================\n",
    "print(\"\\n\" + \"ğŸ¯\" * 25)\n",
    "print(\"AGENTIC RAG SYSTEM - FINAL DEMO\")\n",
    "print(\"ğŸ¯\" * 25)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEMO 1: WEATHER API\")\n",
    "print(\"=\"*70)\n",
    "show_agentic_result(agentic_answer(\"What's the weather in Tel Aviv?\"))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEMO 2: CRYPTO API (BONUS)\")\n",
    "print(\"=\"*70)\n",
    "show_agentic_result(agentic_answer(\"What is the current price of Ethereum?\"))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEMO 3: RAG (IR)\")\n",
    "print(\"=\"*70)\n",
    "show_agentic_result(agentic_answer(\"Explain the BM25 ranking algorithm and how it works.\"))\n",
    "\n",
    "print(\"\\nâœ… All demos completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b9d2d6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Interactive demo ready (uncomment to use)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 12: Interactive demo (optional)\n",
    "# =========================\n",
    "def interactive_demo():\n",
    "    \"\"\"\n",
    "    Interactive loop for testing queries.\n",
    "    Type 'exit' to quit.\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ¤– Interactive Agentic RAG Demo\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Try queries like:\")\n",
    "    print(\"  - 'What's the weather in London?'\")\n",
    "    print(\"  - 'What is the price of bitcoin?'\")\n",
    "    print(\"  - 'Explain inverted index'\")\n",
    "    print(\"Type 'exit' to quit\")\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nğŸ’¬ Your query: \").strip()\n",
    "\n",
    "            if query.lower() in ['exit', 'quit', 'q']:\n",
    "                print(\"ğŸ‘‹ Goodbye!\")\n",
    "                break\n",
    "\n",
    "            if not query:\n",
    "                continue\n",
    "\n",
    "            print()\n",
    "            result = agentic_answer(query)\n",
    "            show_agentic_result(result)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nğŸ‘‹ Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "\n",
    "# Uncomment to run interactive demo:\n",
    "# interactive_demo()\n",
    "\n",
    "print(\"âœ“ Interactive demo ready (uncomment to use)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb19e740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Interactive demo ready (uncomment to use)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 13: Summary stats\n",
    "# =========================\n",
    "avg_size = sum(len(c.page_content) for c in chunks) // max(1, len(chunks))\n",
    "\n",
    "print(\"\\n\" + \"ğŸ“Š\" * 25)\n",
    "print(\"SYSTEM SUMMARY\")\n",
    "print(\"ğŸ“Š\" * 25)\n",
    "print(f\"ğŸ“ Documents loaded: {len(docs)}\")\n",
    "print(f\"ğŸ“„ Chunks created: {len(chunks)}\")\n",
    "print(f\"ğŸ” Average chunk size: {avg_size} chars\")\n",
    "print(\"ğŸ’¾ Vector store: FAISS (local)\")\n",
    "print(\"ğŸ“¡ Embeddings: sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"ğŸ¤– LLM: Groq (llama-3.1-8b-instant)\")\n",
    "print(\"\\nğŸ› ï¸ Tools:\")\n",
    "print(\"  1) RAG\")\n",
    "print(\"  2) Weather API (Open-Meteo)\")\n",
    "print(\"  3) Crypto API (CoinGecko) â­ BONUS\")\n",
    "print(\"\\nâœ… Status: READY\")\n",
    "print(\"ğŸ“Š\" * 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fdf795f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“Š\n",
      "SYSTEM SUMMARY\n",
      "ğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“Š\n",
      "ğŸ“ Documents loaded: 1\n",
      "ğŸ“„ Chunks created: 5\n",
      "ğŸ” Average chunk size: 693 chars\n",
      "ğŸ’¾ Vector store: FAISS (local)\n",
      "ğŸ“¡ Embeddings: sentence-transformers/all-MiniLM-L6-v2\n",
      "ğŸ¤– LLM: Groq (llama-3.1-8b-instant)\n",
      "\n",
      "ğŸ› ï¸ Tools:\n",
      "  1) RAG\n",
      "  2) Weather API (Open-Meteo)\n",
      "  3) Crypto API (CoinGecko) â­ BONUS\n",
      "\n",
      "âœ… Status: READY\n",
      "ğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“ŠğŸ“Š\n"
     ]
    }
   ],
   "source": [
    "# Cell 13-SYSTEM SUMMARY\n",
    "avg_size = sum(len(c.page_content) for c in chunks) // max(1, len(chunks))\n",
    "\n",
    "print(\"\\n\" + \"ğŸ“Š\" * 25)\n",
    "print(\"SYSTEM SUMMARY\")\n",
    "print(\"ğŸ“Š\" * 25)\n",
    "print(f\"ğŸ“ Documents loaded: {len(docs)}\")\n",
    "print(f\"ğŸ“„ Chunks created: {len(chunks)}\")\n",
    "print(f\"ğŸ” Average chunk size: {avg_size} chars\")\n",
    "print(\"ğŸ’¾ Vector store: FAISS (local)\")\n",
    "print(\"ğŸ“¡ Embeddings: sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"ğŸ¤– LLM: Groq (llama-3.1-8b-instant)\")\n",
    "print(\"\\nğŸ› ï¸ Tools:\")\n",
    "print(\"  1) RAG\")\n",
    "print(\"  2) Weather API (Open-Meteo)\")\n",
    "print(\"  3) Crypto API (CoinGecko) â­ BONUS\")\n",
    "print(\"\\nâœ… Status: READY\")\n",
    "print(\"ğŸ“Š\" * 25)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
